spec:
  destination:
    type: server
    clusterInfo: https://kubernetes.default.svc
  project: default

global:
  # 기본시나리오에서는 privateRegistry값만 변경해주면 된다
  # e.x) 172.22.6.2:5000 or hyperregistry.domain.com
  privateRegistry: test-registry.com
  # 값 변경 필요 없음
  adminUser: test@test.co.kr
  cluster: master
  clusterName: in-cluster
  clusterNamespace: default
  domain: testdomain.com

modules:
  ### calico
  calico:
    enabled: false

  ### gitlab
  gitlab:
    enabled: true
    subdomain: gitlab
    pvc:
      storage: 30Gi
    # default로 주는 경우 default storage class를 사용
    # default를 사용하지 않고 싶은 경우에는 storage class이름을 기입
    # 미리 설치된 gitlab과 sync해야 하는 경우 default storageclass는 사용할 수 없음    
      storageClassName: "nfs"
    oidc:
      enabled: false

  ### gitea
  gitea:
    enabled: false
    subdomain: gitea

  ### gateway-bootstrap
  gatewayBootstrap:
    enabled: true
    # cloud provider의 load balancer 서비스(ex. aws nlb)를 사용하기 위해서는
    # LoadBalancer로 값을 변경
    svc_type: NodePort
    tls:
      selfsigned:
        enabled: false
      # acme로 할 경우, domain에 입력한 주소를 가지고 있어야함
      acme:
        enabled: false
        email: test@tmax.co.kr
        dns:
          type: route53
          accessKeyID: accesskey
          accessKeySecret: secretkey
          hostedZoneID: hostedzoneid
        # acme를 통한 인증서 발급의 경우, rate limit이 존재하므로 테스트를 위한 설정값이 따로 존재함
        # 자세한 내용은 https://letsencrypt.org/docs/staging-environment/#rate-limits 참조
        # staging / production 중 택1하여 기입하여야 하며, 각각 테스트용 / 운영용을 의미함
        environment: production
    certManager:
      enabled: true
      # default 300
      syncWaitTime: 300
    console:
      enabled: true
      multiCluster:
        enabled: true
      # default 0
      syncWaitTime: 0
      subdomain: console
    gateway:
      enabled: true
      # default 120
      syncWaitTime: 120
    jwtDecodeAuth:
      enabled: true
      # default 30
      syncWaitTime: 30

  ### strimzi-kafka-operator
  strimziKafka:
    enabled: true

  ### service-binding-operator
  serviceBinding:
    enabled: true
    
  ### hyperauth
  hyperAuth:
    enabled: true
    svcType: Ingress
    subdomain: hyperauth
    # default로 주는 경우 default storage class를 사용
    # default를 사용하지 않고 싶은 경우에는 storage class이름을 기입
    storageClass: default
    # do not edit tmaxClientSecret!
    tmaxClientSecret: tmax_client_secret

  ### efk
  efk:
    enabled: false
    es:
      version: 7.2.1
      limitMemory: 8Gi
      requestMemory: 5Gi
      jvmHeap: "-Xms4g -Xmx4g"
      volumeSize: 50Gi
    busyBox:
      version: 1.32.0
    kibana:
      version: 7.2.0
      svcType: ClusterIP
      subdomain: kibana
    gatekeeper:
      version: 10.0.0
    fluentd:
      version: v1.4.2-debian-elasticsearch-1.1

  ### argocd
  argocd:
    enabled: true
    subdomain: argocd
    repoServer:
      replicas: 1
    redis:
      replicas: 1
    argocdServer:
      replicas: 1
    controller:
      replicas: 1
    ingress:
      enableTraefik: true
      secretName:
     
  ### opensearch
  opensearch:
    enabled: true
    os:
      version: 1.2.3
      limitMemory: 8Gi
      requestMemory: 5Gi
      jvmHeap: "-Xms4g -Xmx4g"
      volumeSize: 50Gi
    busyBox:
      version: 1.32.0
    dashboard:
      version: 1.2.0
      svcType: ClusterIP
      subdomain: opensearch-dashboard
    fluentd:
      version: fluentd-v1.4.2-debian-elasticsearch-1.1
      # default로 주는 경우 default storage class를 사용
      # default를 사용하지 않고 싶은 경우에는 storage class이름을 기입
      storageClass: default
  
  ### Loki
  loki:
    enabled: true
    loki: 
      version: 2.6.0
      volumeSize: 50Gi
      storageClass: default
    promtail:
      version: 2.6.0
  
  ### prometheus
  prometheus:
    enabled: true
    versions:
      prometheus: v2.30.3
      cmReload: v0.0.1
      cmReloader: v0.51.2
      operator: v0.51.2
      alertManager: v0.23.0
      kubeRbacProxy: v0.11.0
      kubeStateMetrics: v2.2.3
      nodeExporter: v1.2.2
      adapter: v0.9.1
    pvcSize: 10Gi

  ### grafana-operator
  grafanaOperator:
    enabled: true
    subdomain: grafana
    pvcSize: 10Gi
    operator: 
      version: v0.0.10
      imageRepo: docker.io/tmaxcloudck/grafana-operator
    grafana:
      version: "8.2.2"
      imageRepo: grafana/grafana


  ### service-mesh
  serviceMesh:
    ### istio
    istio:
      enabled: true

    ### jaeger
    jaeger:
      enabled: true
      subdomain: jaeger

    ### kiali
    kiali:
      enabled: true
      subdomain: kiali

  ### cluster-api
  capi:
    enabled: true
    providers:
      aws:
        enabled: true
        # description: ...
        # credential은 다음과 같이 생성
        # cat << EOF | base64
        # > [default]
        # > aws_access_key_id = {{ AWS ACCESS KEY }}
        # > aws_secret_access_key = {{ AWS SECRET ACCESS KEY }} 
        # > region = {{ default region}} ex) ap-northeast-2
        # > EOF
        credentials: "VGhpcyBpcyBhbiBhd3MgY3JlZGVudGlhbAo="
      vsphere:
        enabled: true
        credentials:
          username: "user"
          password: "password"

  ### template service broker
  tsb:
    enabled: true
    version: 0.1.4
    clusterTsb:
      version: 0.1.4
    templateOperator:
      version: 0.2.7

  ### catalog controller
  catalogController:
    enabled: true

  ### helm-apiserver
  helmApiserver:
    enabled: true
    version: 0.0.5
    subdomain: helm
    # default로 주는 경우 default storage class를 사용
    # default를 사용하지 않고 싶은 경우에는 storage class이름을 기입
    storageClass: default
    # 지정 가능: fatal(0), error(1), warn(2), info(3), debug(4), trace(5)
    logLevel: error

  ### hypercloud
  hyperCloud:
    enabled: true
    # description: 'single' or 'multi'
    mode: multi
    kafka:
      enabled: true
    kubectl:
      timeout: 21600
    # default로 주는 경우 default storage class를 사용
    # default를 사용하지 않고 싶은 경우에는 storage class이름을 기입
    storageClass: default
    
    # multi-operator의 경우, info, debug, error 기입 가능(대소문자 유의)
    multiOperator:
      logLevel: info
    # single-operator의 경우, info, debug, error 기입 가능(대소문자 유의)
    singleOperator:
      logLevel: info
    # hypercloud api server의 경우, TRACE, DEBUG, INFO, WARN, ERROR, FATAL 기입 가능(대소문자 유의)
    apiServer:
      logLevel: INFO
    # timescaledb.<테이블 이름>.chunk : 청크 테이블이 생성되는 시간 단위
    # timescaledb.<테이블 이름>.retention : 청크 테이블 보관 기간
    timescaledb:
      # timescaledb의 경우, DEBUG5, DEBUG4, DEBUG3, DEBUG2, DEBUG1, INFO, NOTICE, WARNING, ERROR, LOG, FATAL, PANIC 기입 가능(대소문자 유의)
      logLevel: WARNING
      audit:
        chunk: "7 days"
        retention: "1 years"
      event:
        chunk: "1 days"
        retention: "1 months"
      metering_hour:
        chunk: "1 days"
        retention: "1 months"
      metering_day:
        chunk: "1 months"
        retention: "1 years"
      metering_month:
        chunk: "1 years"
        retention: "1 years"
      metering_year:
        chunk: "1 years"
        retention: "10 years"

  ### hyperregistry
  hyperregistry:
    enabled: true
    core:
      subdomain: hyperregistry
    notary:
      subdomain: hyperregistry-notary
    # core, chartmuseum, jobservice, notary-server, notary-signer, registry, trivy의 경우 다음 아래의 로그레벨 설정으로 debug, info, warning, error, fatal 기입 가능 (대소문자 유의)
    mains:
      logLevel: info
    # redis의 경우 debug, verbose, notice, warning 기입 가능 (대소문자 유의, warning은 error 급) 
    redis:
      logLevel: warning
    # database(postgres)의 경우 DEBUG5, DEBUG4, DEBUG3, DEBUG2, DEBUG1, INFO, NOTICE, WARNING, ERROR, LOG, FATAL, PANIC 기입 가능(대소문자 유의)
    database:
      logLevel: ERROR
    # portal의 경우 debug, info, notice, warn, error, crit, alert, emerg 기입 가능 (대소문자 유의)
    portal:
      logLevel: error
    storageClass: nfs
    storageClassDatabase: nfs

  ### tekton pipeline
  tektonPipeline:
    enabled: true
    #namespace: tekton-pipelines

  ### tekton trigger
  tektonTrigger:
    enabled: true

  ### cicd operator
  cicd:
    enabled: true
    subdomain: cicd-webhook

  ### redis-operator
  redis:
    enabled: true

  ### image validating webhook
  imageValidatingWebhook:
    enabled: true
      # debug, info, error 기입 가능 (대소문자 유의)
    logLevel: error

  ### nfs-subdir-external-provisioner
  nfs:
    enabled: false
    # nfs provisioner가 사용할 nfs server, ex: 192.168.7.16
    server: 192.168.7.16
    # nfs provisioner가 사용할 nfs server의 path, ex: /mnt/nfs-shared-dir
    path: /nfs-storage
    # nfs provisioner를 default storageClass로 설정, ex: default / not
    defaultClass: not

  ### ceph-csi-cephfs
  cephfs:
    enabled: false
    # ceph clusterID(fsid)
    clusterId: 50611be6-33b3-11eb-a5cb-0894ef32cba4
    # ceph monitor들 IP:PORT
    monitors: '["192.168.7.16:3300","192.168.7.16:6789","192.168.7.17:3300","192.168.7.17:6789"]'
    # ceph admin key, /etc/ceph의 ceph.client.admin.keyring
    key: AQCeBcZftAEvExAAultsKBpNpiWWGi06Md7mmw==
    # cephfs csi를 default storageClass로 설정, ex: default / not
    defaultClass: not

  ### ceph-csi-rbd
  rbd:
    enabled: false
    # ceph clusterID(fsid)
    clusterId: 50611be6-33b3-11eb-a5cb-0894ef32cba4
    # ceph monitor들 IP:PORT
    monitors: '["192.168.7.16:3300","192.168.7.16:6789","192.168.7.17:3300","192.168.7.17:6789"]'
    # ceph admin key, /etc/ceph의 ceph.client.admin.keyring
    key: AQCeBcZftAEvExAAultsKBpNpiWWGi06Md7mmw==
    # rbd csi를 default storageClass로 설정, ex: default / not
    defaultClass: not
  
  ### efs-csi
  efs:
    enabled: false
    # efs ID
    fileSystemId: fs-0ce741ec0e2ea2fa2
    # efs csi를 default storageClass로 설정, ex: default / not
    defaultClass: not